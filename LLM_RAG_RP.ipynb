{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nltk in /home/user/.local/lib/python3.10/site-packages (3.8.1)\n",
            "Requirement already satisfied: joblib in /home/user/.local/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/user/.local/lib/python3.10/site-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /home/user/.local/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from enum import Enum\n",
        "from operator import itemgetter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcG4VN92SbZi"
      },
      "source": [
        "# Loading / Splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ea52IZJSg1E",
        "outputId": "04bb45dc-3029-4c07-8ba1-3662bb5fe0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AS-BIKE-SHOP-WEB-MANUAL.pdf\n",
            "dyson_contrarotator.pdf\n",
            "101\n"
          ]
        }
      ],
      "source": [
        "# Load and split documents\n",
        "pdf_directory = \"./PDF_FILES\"\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=25, add_start_index=True)\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\n",
        "\n",
        "all_docs = []\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdfloader = PyPDFLoader(os.path.join(pdf_directory, filename))\n",
        "        docs = pdfloader.load()\n",
        "        all_docs.extend(docs)\n",
        "\n",
        "print(len(all_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embedding Phase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Embedding Phase\n",
        "sentence_transformer_ef = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma(collection_name=\"full_documents\", embedding_function=sentence_transformer_ef)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieving Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bike. Again be careful not to push the rivetout of thelink!If someone brings a bike in without a chainor you\n",
            "========\n",
            "1.Inspect the chain forrust, broken, twisted or bentlinks. Anoverly rusted chain that cannot bendneedsto be replaced.Achain with \"play\" in its links is indicative of wearand the chainmay need to be replaced. Use thechain checkertooltomeasure the amount of play in a suspect multi-speedchain.(Ask a fellow mechanic how to use this tool). Usethe chainbreaker tool to break the chain as stated in theSingleSpeedChain Replacement Tutorial. *Do not push the pin allthe wayout.2.Next, get the correct size chain that correspondswith thenumber of speeds on the rear wheel of the bike.3.Again, new chains will likely have excess chains thatneed to beremoved to match the size of the old chain. Lay thenew andold chain next to each other and align each link toidentify thelink where the new chain must be broken. Remove thelinkwith the same technique used to originally removethe chainfrom the bike. Again be careful not to push the rivetout of thelink!If someone brings a bike in without a chainor you\n"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "\n",
        "store = InMemoryStore()\n",
        "retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")\n",
        "\n",
        "retriever.add_documents(all_docs)\n",
        "len(list(store.yield_keys()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Answer generation phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FDQYkRvN3d1n",
        "outputId": "caf71266-f0d2-4f23-cace-1f7352fa069e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parent run dd91b487-0c95-4c7b-aaed-57bb6682f709 not found for run 479b7502-e4c5-4bcb-abfb-5e10012960a3. Treating as a root run.\n",
            "Parent run 350875c7-e493-48e0-a6f3-ff0d5ce20cc4 not found for run 07cf0aa0-908f-47d5-bba1-9427f4f86c4d. Treating as a root run.\n",
            "Parent run 285b458e-ba15-4cd7-891a-328e1ab5d647 not found for run 5586c974-8ac5-408c-a7c0-8d2c49f41198. Treating as a root run.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    # Prompt for the API key if it is empty\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt=\"Enter your OpenAI API key: \")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "### Contextualize question ###\n",
        "contextualize_q_system_prompt = (\n",
        "    \"Given a chat history and the latest user question \"\n",
        "    \"which might reference context in the chat history, \"\n",
        "    \"formulate a standalone question which can be understood \"\n",
        "    \"without the chat history. Do NOT answer the question, \"\n",
        "    \"just reformulate it if needed and otherwise return it as is.\"\n",
        ")\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")\n",
        "### Answer question ###\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "### Statefully manage chat history ###\n",
        "store = {}\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")\n",
        "\n",
        "\n",
        "def chat(inp):\n",
        "  \"\"\"Function to handle user input and return Bard's response\"\"\"\n",
        "  user_input = inp\n",
        "  if not user_input:\n",
        "    return None\n",
        "  answer = conversational_rag_chain.invoke(\n",
        "      {\"input\": user_input},\n",
        "      config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        "  )[\"answer\"]\n",
        "  return f\"\\nYou: {user_input}\\nBard: {answer}\"\n",
        "\n",
        "\n",
        "# Define the chat interface\n",
        "interface = gr.Interface(\n",
        "  fn=chat,\n",
        "  inputs=gr.Textbox(placeholder=\"Type your question here...\"),\n",
        "  outputs=gr.Textbox(value=\"\"),\n",
        "  title=\"Chat with me\",\n",
        "  description=\"Ask me anything!\",\n",
        "  elem_id=\"chat-container\",\n",
        ")\n",
        "\n",
        "# Display the interface\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
