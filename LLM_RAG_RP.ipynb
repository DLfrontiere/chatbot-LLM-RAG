{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0F3KTZ433eT",
        "outputId": "13f912b8-73bb-4bb9-9026-ab2fec91ca74"
      },
      "outputs": [],
      "source": [
        "#@title setup packages\n",
        "\n",
        "\n",
        "# Import necessary modules\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from operator import itemgetter\n",
        "import bs4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOa6ST1gSHAp"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOiiLzHZSHL_",
        "outputId": "c2b7a8bf-3834-402c-ff71-e1716cf5f5dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43131"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading and storing datasets\n",
        "# Load documents (e.g., from local storage)\n",
        "#document_loader = DocumentLoader(\"path_to_local_storage\")\n",
        "\n",
        "#Loading from web\n",
        "# Only keep post title, headers, and content from the full HTML.\n",
        "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "len(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcG4VN92SbZi"
      },
      "source": [
        "# Splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ea52IZJSg1E",
        "outputId": "04bb45dc-3029-4c07-8ba1-3662bb5fe0ff"
      },
      "outputs": [],
      "source": [
        "#Define different text splitter methods\n",
        "# Recursive Character Text Splitter\n",
        "import os\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from  langchain_community.document_loaders.pdf import PyPDFLoader\n",
        "\n",
        "all_docs = []\n",
        "all_splits = []\n",
        "\n",
        "pdf_directory = \"./\"\n",
        "\n",
        "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000, add_start_index=True)\n",
        "\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdfloader = PyPDFLoader(os.path.join(pdf_directory,filename))\n",
        "        docs = pdfloader.load_and_split(text_splitter=recursive_splitter)\n",
        "        \n",
        "        for doc in docs:\n",
        "            all_docs.append(doc)\n",
        "        \n",
        "\n",
        "\n",
        "# HTML Header Text Splitter\n",
        "#html_splitter = HTMLHeaderTextSplitter()\n",
        "\n",
        "# Markdown Header Text Splitter\n",
        "#markdown_splitter = MarkdownHeaderTextSplitter()\n",
        "\n",
        "# Code Text Splitter\n",
        "#code_splitter = CodeTextSplitter()\n",
        "\n",
        "# Token Text Splitter\n",
        "#token_splitter = TokenTextSplitter()\n",
        "\n",
        "# Character Text Splitter\n",
        "#character_splitter = CharacterTextSplitter()\n",
        "\n",
        "# Semantic Chunker\n",
        "#semantic_chunker = SemanticChunker()\n",
        "\n",
        "# AI21 Semantic Text Splitter\n",
        "#ai21_splitter = AI21SemanticTextSplitter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embedding Phase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utente/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/home/utente/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "2024-06-18 17:24:28.224907: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-18 17:24:29.528824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/home/utente/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define documents\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "\n",
        "sentence_transformer_ef = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "embedding_function = sentence_transformer_ef \n",
        "\n",
        "# Embed and store document splits\n",
        "vectorstore = Chroma.from_documents(documents=all_docs, embedding=embedding_function)\n",
        "\n",
        "\n",
        "# Other embedding models are available in:\n",
        "# - lang_chain_embedding_models\n",
        "# - sentence-transformers\n",
        "# - Kaggle (includes all ML models, not just embedding ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieving Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='UK  0870 600 2701 \\nOpen 7 days a week, 8am â€“ 8pm\\nROI  (01)475 7109\\nDyson Ltd  Tetbury Hill  Malmesbury\\nWiltshire  SN16 ORP\\nwww.dyson .com \\nJN.6596 30.01.02 PN.50351-01-02' metadata={'page': 23, 'source': './50675-01.pdf', 'start_index': 0}\n",
            "page_content='This user guide also contains tips on effective\\nwashing and important safety notes.Please read this user guide carefully before use.User guide\\nTM\\nwww.dyson.com' metadata={'page': 0, 'source': './50675-01.pdf', 'start_index': 0}\n",
            "page_content='The only 2-drum wash action.Dyson ContrarotatorTM\\nConventional washing machines may seem convenient, \\nbut their poor performance lets you down. So James Dysonasked his engineers to experiment with every imaginable wayof washing to design a better washing machine.\\nAlong the way, Dyson engineers made a surprising discovery:\\nwashing by hand gave better wash results than single drummachines. Because the laundry is constantly on the move, it is manipulated and flexed. This opens the fabric to thedetergent, releasing dirt quickly and effectively.\\nTo replicate the movement of washing by hand, Dyson\\nengineers designed two aligned drums and engineered themto rotate in opposite directions at the same time: laundry isconstantly on the move, manipulated and flexed. \\nBecause the Contrarotator\\nTMreleases dirt more effectively, \\nit can wash laundry cleaner, faster and in larger loads.\\nThis product is protected by the following:\\nPatents and Patent Applications:\\nRegistered Designs:\\nGB 2090907 DE 40008214.4 FR 004914 AU 143433\\nCH 127265 IT MI 2000 O 000588 JP 1114510 US 29/128,794\\nTrade Marks:\\nDYSONTMCONTRAROTATORTM DYSON CONTRAROTATORTMCRO1TMROLLERJACKTM\\nEquivalent rights exist in other territories.\\nFor patent information please see www. dyson .com201\\nGB 00 01848.1\\nGB 01 21535.9US 09/853,689WO 01/71086WO 01/88256WO 01/71084\\nWO 01/71085PCT/GB 01/03730US 09/956,248WO 01/71087WO 01/73939\\nWO 01/71083PCT/GB01/03716PCT/GB01/04324US 09/956,163GB 2 337 274\\nUS 6,311,527EP 1078119JP 2000-548539US 09/853,689WO 00/68490\\nPCT/GB01/02974WO 99/58753CA 2,332,024AU 39393/99' metadata={'page': 4, 'source': './50675-01.pdf', 'start_index': 0}\n",
            "page_content='Contents\\nOverview of your Dyson ContrarotatorTM\\nThe only 2-drum wash action\\nFree registration\\nImportant safety notes\\nInner transit packaging removal\\nMoving the ContrarotatorTM\\nSpecificationLocationDrainage, water supply and electricityDrainageWater supplyElectrical installationAfter installation\\nLoading the Contrarotator\\nTM\\nDetergent useTo start your wash, using default settingsTo personalise the default wash programmesFabric care\\nProgramme table\\nCleaning\\nCoin trapWater filter Emergency door release\\nTroubleshooting01\\n0101\\n010102\\n03\\n0101\\n0101\\n02\\n01\\n0203\\n01\\n0203Overview\\nDyson ContrarotatorTM\\nUser Instructions \\nBefore installation \\nInstallation\\nOperation\\nStarting your wash\\nOptional settings\\nFabric care and Programme table\\nMaintenance\\nTroubleshooting1\\n23\\n45\\n6\\n7\\n89\\n10\\n11' metadata={'page': 2, 'source': './50675-01.pdf', 'start_index': 0}\n",
            "page_content='Overview of your Dyson ContrarotatorTM1 01 Overview\\nOuter doorControl panel Soap trayHot water inlet Cold water inlet \\nDrainage hose hook Power cable & plug\\n&\\nInner doorRating plate\\nAdjustable feetDrainage hose & adjustable clip\\nRollerjackTMCoin trap401 601 & 501 502 & 501 502\\n502\\n503 4011002601601\\n601301 &1001 701&801\\nHot & cold leak protection\\ninlet hoses\\nCRO1 Flowcheck and Memory only\\n501&502501&502Dyson guarantee form\\nReply envelopeFabric care leaflet & letter\\nDyson spanner\\n401&501\\nHot & cold inlet hoses\\n501&502' metadata={'page': 3, 'source': './50675-01.pdf', 'start_index': 0}\n",
            "page_content='/K36/K30/K30 /K6D/K6D\\n/K4D/K41/K58/K2E/K34/K35/K30 /K6D/K6D\\n/K4D/K49/K4E/K2E/K38/K34/K38 /K6D/K6D/K35/K39/K35/K6D/K6DDimensions: Height 848mm, depth 575mm, width 595mm\\nWeight: 103kg.\\nVoltage: 220-240V , 50Hz. Please refer to rating plate \\n(see section 1 01 for location).\\nPower: 2750W (230V). Please refer to rating plate \\n(see section     101 for location).\\nWater pressure: 0.4-5 bar.\\nCapacity: 7kg dry laundry (maximum).\\nLocation\\nEvery Dyson washing machine is tested before it leaves the\\nfactory. As a result, there may be some dampness or water inthe machine.\\nâ€¢ The machine should not be installed in a location where the\\ntemperature may drop below freezing.\\nâ€¢ The machine should not be installed in a bathroom.â€¢ The machine must be installed on a secure and flat surface.\\nSoft floors, such as carpet or carpet tiles, are not suitable.\\nThe layout of the drainage taps and power socket and their\\ndistance from the machine are illustrated below. The waterinlet hoses, drainage hose and electrical mains lead must bepositioned carefully to avoid damage or kinks when themachine is in use. The machine can be connected to astandpipe, under-sink pipe connection or other drainagesystem, but the critical dimensions must be adhered to.\\nImportant      SpecificationInstallation\\nDrainage using a sink pipe*\\nDrainage, water supply and electricity\\nThe washing machine comes with:\\n2 inlet hoses or2 leak protection inlet hoses \\nCRO1 Flowcheck and Memory only\\n1 drainage hose hook1 Dyson spanner1 drainage hose at the back of the machine\\nThe above items are found in the drum unless stated otherwise.\\nNB: The leak protection hoses can be fitted to either\\nsupply, ensuring that the valve end is attached directly to the water mains. Take care not to cross the hoses eg: hot outlet to cold inlet.5 01\\n/K36/K30/K30 /K6D/K6D\\n/K4D/K41/K58/K2E\\n/K34/K35/K30 /K6D/K6D\\n/K4D/K49/K4E/K2E\\nDrainage using a stand pipe*Cold inlet hose\\nHot inlet hose\\nDrainage hose hook\\nNote: CRO1 Flowcheck and Memory have grey leak protection inlet hoses\\n*All hoses can be supplied in 2.5m lengths if required. Please contact the helpline to order.Inlet valve\\nDyson spannerLeak protection\\ninlet hoses' metadata={'page': 7, 'source': './50675-01.pdf', 'start_index': 0}\n"
          ]
        }
      ],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "retrieved_docs = retriever.invoke(\"what did the dyson engineers discovery?\")\n",
        "\n",
        "len(retrieved_docs)\n",
        "\n",
        "for retrieved_doc in retrieved_docs:\n",
        "    print(retrieved_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FDQYkRvN3d1n",
        "outputId": "caf71266-f0d2-4f23-cace-1f7352fa069e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Dyson engineers discovered that washing by hand gave better wash results than single drum machines, leading them to design a better washing machine with two aligned drums rotating in opposite directions."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/utente/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/home/utente/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use create_history_aware_retriever together with create_retrieval_chain (see example in docstring) instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Retrieving top k relevant embeddings\n",
        "def retrieve_top_k(vectorstore, query, k=5, method='cosine'):\n",
        "    if method == 'cosine':\n",
        "        return vectorstore.retrieve(query, k=k, method='cosine')\n",
        "    elif method == 'dot_product':\n",
        "        return vectorstore.retrieve(query, k=k, method='dot_product')\n",
        "    elif method == 'euclidean':\n",
        "        return vectorstore.retrieve(query, k=k, method='euclidean')\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported retrieval method\")\n",
        "\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "  (\"human\", \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Question: {question} Context: {context} Answer:\"),])\n",
        "\n",
        "qa_eval_prompt = ChatPromptTemplate.from_messages([\n",
        "  (\"human\", \"You are an evaluator for question-answer pair.Question: {question}  Answer: {answer} \"),])\n",
        "\n",
        "\n",
        "# Define RAG Chain\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "   {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "   | prompt\n",
        "   | llm\n",
        "   | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain = ( \n",
        "            RunnableParallel(context = retriever | format_docs, question = RunnablePassthrough() ) |\n",
        "            RunnableParallel(answer= prompt | llm | retrieve_answer, question = itemgetter(\"question\"), context = itemgetter(\"context\") ) |\n",
        "            RunnableParallel(input =  qa_eval_prompt | llm_selfeval | json_parser, context = itemgetter(\"context\"))\n",
        "            )\n",
        "\n",
        "user_prompt = \"what did the dyson engineers discovery?\"\n",
        "# Example usage of the RAG chain\n",
        "for chunk in rag_chain.stream(user_prompt):\n",
        "   print(chunk, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "\n",
        "# The prompt is expected to be a dict with keys \"context\" and \"question\".\n",
        "# retriever | format_docs passes the question through the retriever, generating Document objects, and then to format_docs to generate strings;\n",
        "# RunnablePassthrough() passes through the input question unchanged;\n",
        "# llm runs the inference;\n",
        "# StrOutputParser() plucks the string content out of the LLM's output message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
